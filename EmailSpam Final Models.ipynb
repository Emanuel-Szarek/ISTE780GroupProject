{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "import pickle\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources \n",
    "https://stackabuse.com/text-classification-with-python-and-scikit-learn/\n",
    "Previous class projects\n",
    "https://scikit-learn.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv(\"spam_or_not_spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>martin a posted tassos papadopoulos the greek ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>man threatens explosion in moscow thursday aug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>klez the virus that won t die already the most...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in adding cream to spaghetti carbonara which ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  label\n",
       "0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0\n",
       "1  martin a posted tassos papadopoulos the greek ...      0\n",
       "2  man threatens explosion in moscow thursday aug...      0\n",
       "3  klez the virus that won t die already the most...      0\n",
       "4   in adding cream to spaghetti carbonara which ...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.372740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label\n",
       "count  3000.000000\n",
       "mean      0.166667\n",
       "std       0.372740\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       0.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DF.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = DF.email \n",
    "y = DF.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turning our strings into a matrix of tokens \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "Email_Vectorizer = CountVectorizer(stop_words=stopwords.words('english'))\n",
    "X = Email_Vectorizer.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partition our data into training and data sets of 20% test and 80% train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuel.s/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit our RandomForest classifier\n",
    "Rand_For = RandomForestClassifier()\n",
    "Rand_For.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Rand_For.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       510\n",
      "           1       0.94      0.86      0.90        90\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.92      0.94       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  505\n",
      "False Positive - Spam:  5\n",
      "False Negative - Not Spam:  13\n",
      "True Positive - Spam:  77\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chaning testing set to only 10% instead of 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuel.s/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rand_For = RandomForestClassifier()\n",
    "Rand_For.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       253\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.98       300\n",
      "   macro avg       0.98      0.93      0.95       300\n",
      "weighted avg       0.98      0.98      0.98       300\n",
      "\n",
      "0.9766666666666667\n"
     ]
    }
   ],
   "source": [
    "y_pred = Rand_For.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  252\n",
      "False Positive - Spam:  1\n",
      "False Negative - Not Spam:  6\n",
      "True Positive - Spam:  41\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the random state of from 0 to 5.  This controls the amount the data is shuffled before being split up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuel.s/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=5, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rand_For = RandomForestClassifier(random_state=5)\n",
    "Rand_For.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       499\n",
      "           1       0.98      0.85      0.91       101\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.97      0.92      0.95       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "0.9716666666666667\n"
     ]
    }
   ],
   "source": [
    "#Depending on how the data is split, the accuracy can get better or worse than the 0 randomness.\n",
    "y_pred = Rand_For.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  497\n",
      "False Positive - Spam:  2\n",
      "False Negative - Not Spam:  15\n",
      "True Positive - Spam:  86\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing random state to 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuel.s/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=15, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "Rand_For = RandomForestClassifier(random_state=15)\n",
    "Rand_For.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       518\n",
      "           1       0.95      0.84      0.89        82\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.92      0.94       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "0.9716666666666667\n"
     ]
    }
   ],
   "source": [
    "#Just like the previous one, the accuracy gets better and worse, it depends on the split\n",
    "y_pred = Rand_For.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  514\n",
      "False Positive - Spam:  4\n",
      "False Negative - Not Spam:  13\n",
      "True Positive - Spam:  69\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the RandomForest criterion from gini to entropy - Changing the way the classifier measures the quality of each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuel.s/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "Rand_For = RandomForestClassifier(criterion = 'entropy')\n",
    "Rand_For.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       510\n",
      "           1       0.96      0.84      0.90        90\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.97      0.92      0.94       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "0.9716666666666667\n"
     ]
    }
   ],
   "source": [
    "#Even if run multiple times, the outcome is usually better than the gini counterpart\n",
    "y_pred = Rand_For.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  507\n",
      "False Positive - Spam:  3\n",
      "False Negative - Not Spam:  14\n",
      "True Positive - Spam:  76\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying entropy again except making the random state 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuel.s/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=5, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "Rand_For = RandomForestClassifier(criterion = 'entropy', random_state =5)\n",
    "Rand_For.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       499\n",
      "           1       0.95      0.91      0.93       101\n",
      "\n",
      "    accuracy                           0.98       600\n",
      "   macro avg       0.97      0.95      0.96       600\n",
      "weighted avg       0.98      0.98      0.98       600\n",
      "\n",
      "0.9766666666666667\n"
     ]
    }
   ],
   "source": [
    "#Same as the others, depending on the split, the accuracy can get better or worse.\n",
    "y_pred = Rand_For.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  494\n",
      "False Positive - Spam:  5\n",
      "False Negative - Not Spam:  9\n",
      "True Positive - Spam:  92\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation Set of .1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=0)\n",
    "\n",
    "# .7 Training / .1 val / .2 Test\n",
    "# .8 of the original train * .125 will equal .1  Subtract .8 with .1 because .1 is the validation set and .7 is the train\n",
    "#leaving the remaining .2 as the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuel.s/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rand_For = RandomForestClassifier()\n",
    "Rand_For.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       247\n",
      "           1       0.98      0.91      0.94        53\n",
      "\n",
      "    accuracy                           0.98       300\n",
      "   macro avg       0.98      0.95      0.96       300\n",
      "weighted avg       0.98      0.98      0.98       300\n",
      "\n",
      "0.98\n"
     ]
    }
   ],
   "source": [
    "#Adding a validation set seems to bounce around the accuracy ratings as the previous models\n",
    "y_pred = Rand_For.predict(X_val)\n",
    "print(classification_report(y_val,y_pred))\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  246\n",
      "False Positive - Spam:  1\n",
      "False Negative - Not Spam:  5\n",
      "True Positive - Spam:  48\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation Set of .1 Using entropy instead of gini\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuel.s/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rand_For = RandomForestClassifier(criterion = \"entropy\")\n",
    "Rand_For.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       247\n",
      "           1       0.96      0.98      0.97        53\n",
      "\n",
      "    accuracy                           0.99       300\n",
      "   macro avg       0.98      0.99      0.98       300\n",
      "weighted avg       0.99      0.99      0.99       300\n",
      "\n",
      "0.99\n"
     ]
    }
   ],
   "source": [
    "#This acutally seems to be the most consistent and high accuracy!\n",
    "y_pred = Rand_For.predict(X_val)\n",
    "print(classification_report(y_val,y_pred))\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  245\n",
      "False Positive - Spam:  2\n",
      "False Negative - Not Spam:  1\n",
      "True Positive - Spam:  52\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation Set of .1 and using a randomstate of 5\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuel.s/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=5, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rand_For = RandomForestClassifier(random_state=5)\n",
    "Rand_For.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       250\n",
      "           1       0.92      0.90      0.91        50\n",
      "\n",
      "    accuracy                           0.97       300\n",
      "   macro avg       0.95      0.94      0.95       300\n",
      "weighted avg       0.97      0.97      0.97       300\n",
      "\n",
      "0.97\n"
     ]
    }
   ],
   "source": [
    "#Seeems to be about avg, nothing better or worse.\n",
    "y_pred = Rand_For.predict(X_val)\n",
    "print(classification_report(y_val,y_pred))\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  246\n",
      "False Positive - Spam:  4\n",
      "False Negative - Not Spam:  5\n",
      "True Positive - Spam:  45\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation Set of .1 and using a randomstate of 5 and entropy\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuel.s/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=5, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rand_For = RandomForestClassifier(criterion = 'entropy', random_state=5)\n",
    "Rand_For.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       250\n",
      "           1       0.89      0.78      0.83        50\n",
      "\n",
      "    accuracy                           0.95       300\n",
      "   macro avg       0.92      0.88      0.90       300\n",
      "weighted avg       0.95      0.95      0.95       300\n",
      "\n",
      "0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "#Seems to be slightly worse than the other models\n",
    "y_pred = Rand_For.predict(X_val)\n",
    "print(classification_report(y_val,y_pred))\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  245\n",
      "False Positive - Spam:  5\n",
      "False Negative - Not Spam:  11\n",
      "True Positive - Spam:  39\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuel.s/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "Rand_For = RandomForestClassifier()\n",
    "Rand_For.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93833333 0.945      0.965      0.95333333 0.97161937]\n",
      "0.954657206455203\n"
     ]
    }
   ],
   "source": [
    "#cv = 5 means crossfold validation will be set to 5\n",
    "scores_RandForest = cross_val_score(Rand_For, X, y, cv=5, scoring='accuracy')\n",
    "#The score is shown after each fold\n",
    "print(scores_RandForest)\n",
    "print(scores_RandForest.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94       0.94333333 0.94666667 0.96333333 0.96666667 0.97333333\n",
      " 0.92333333 0.97333333 0.97       0.97993311]\n",
      "0.9579933110367895\n"
     ]
    }
   ],
   "source": [
    "scores_RandForest = cross_val_score(Rand_For, X, y, cv=10, scoring='accuracy')\n",
    "#The score is shown after each fold\n",
    "print(scores_RandForest)\n",
    "print(scores_RandForest.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test is going to be split same way as above, just reposting the same code\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train, y_train.values.ravel())\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "#This is quite good\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  449\n",
      "False Positive - Spam:  61\n",
      "False Negative - Not Spam:  39\n",
      "True Positive - Spam:  51\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempting different K-values.  K=1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "knn.fit(X_train, y_train.values.ravel())\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  452\n",
      "False Positive - Spam:  58\n",
      "False Negative - Not Spam:  20\n",
      "True Positive - Spam:  70\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempting different K-values. K=10\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn.fit(X_train, y_train.values.ravel())\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8766666666666667\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  491\n",
      "False Positive - Spam:  19\n",
      "False Negative - Not Spam:  55\n",
      "True Positive - Spam:  35\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempting different K-values. K=15\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "knn.fit(X_train, y_train.values.ravel())\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8916666666666667\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  509\n",
      "False Positive - Spam:  1\n",
      "False Negative - Not Spam:  64\n",
      "True Positive - Spam:  26\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempting different K-values. K=20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "knn = KNeighborsClassifier(n_neighbors = 20)\n",
    "knn.fit(X_train, y_train.values.ravel())\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  510\n",
      "False Positive - Spam:  0\n",
      "False Negative - Not Spam:  66\n",
      "True Positive - Spam:  24\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Log Regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg = LogisticRegression(solver='lbfgs',random_state=0)\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9933333333333333\n"
     ]
    }
   ],
   "source": [
    "y_pred = LogReg.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  510\n",
      "False Positive - Spam:  0\n",
      "False Negative - Not Spam:  4\n",
      "True Positive - Spam:  86\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=5, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LogRegression using random_state of 5\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=5)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg = LogisticRegression(solver='lbfgs',random_state=5)\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "#Smidge worse than 0 random state\n",
    "y_pred = LogReg.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  498\n",
      "False Positive - Spam:  1\n",
      "False Negative - Not Spam:  5\n",
      "True Positive - Spam:  96\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=5, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LogRegression using random_state of 5 also using solver='liblinear' because it is good for smaller datasets like ours\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=5)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg = LogisticRegression(solver='liblinear',random_state=5)\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "#Not much of a change/ or improvement\n",
    "y_pred = LogReg.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  498\n",
      "False Positive - Spam:  1\n",
      "False Negative - Not Spam:  4\n",
      "True Positive - Spam:  97\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=5, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LogRegression using random_state of 5 also using solver='liblinear' because it is good for smaller datasets like ours\n",
    "#Also added a penalty term of L1 instead of L2.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=5)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg = LogisticRegression(solver='liblinear',penalty = 'l1', random_state=5)\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "#Not much of a change/ or improvement\n",
    "y_pred = LogReg.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  496\n",
      "False Positive - Spam:  3\n",
      "False Negative - Not Spam:  3\n",
      "True Positive - Spam:  98\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuel.s/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=5, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LogRegression using random_state of 5 and a balance to the class weight\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=5)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg = LogisticRegression(solver='lbfgs',class_weight='balanced', random_state=5)\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "#Not much of a change/ or improvement\n",
    "y_pred = LogReg.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  498\n",
      "False Positive - Spam:  1\n",
      "False Negative - Not Spam:  4\n",
      "True Positive - Spam:  97\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=5, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LogRegression using random_state of 5 also using solver='liblinear' because it is good for smaller datasets like ours\n",
    "#Also added a penalty term of L1 instead of L2.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=5)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg = LogisticRegression(solver='liblinear',penalty = 'l1',class_weight ='balanced', random_state=5)\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "#Not much of a change/ or improvement\n",
    "y_pred = LogReg.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  495\n",
      "False Positive - Spam:  4\n",
      "False Negative - Not Spam:  1\n",
      "True Positive - Spam:  100\n"
     ]
    }
   ],
   "source": [
    "#Techically it is slightly better because this gives us a flase negative of only 1\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=10, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LogRegression using random_state of 10 and a balance to the class weight\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=10)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg = LogisticRegression(solver='lbfgs',class_weight='balanced', random_state=10)\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9933333333333333\n"
     ]
    }
   ],
   "source": [
    "#Not much of a change/ or improvement\n",
    "y_pred = LogReg.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  504\n",
      "False Positive - Spam:  3\n",
      "False Negative - Not Spam:  1\n",
      "True Positive - Spam:  92\n"
     ]
    }
   ],
   "source": [
    "#Techically it is slightly better because this gives us a flase negative of only 1\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=10, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LogRegression using random_state of 10 and a balance to the class weight, libinear solver and l1 penalty\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=10)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg = LogisticRegression(solver='liblinear',penalty = 'l1',class_weight='balanced', random_state=10)\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "#Not much of a change/ or improvement\n",
    "y_pred = LogReg.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  503\n",
      "False Positive - Spam:  4\n",
      "False Negative - Not Spam:  2\n",
      "True Positive - Spam:  91\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=10, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LogRegression using random_state of 10 and a balance to the class weight, libinear solver \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=10)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg = LogisticRegression(solver='liblinear',class_weight='balanced', random_state=10)\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9933333333333333\n"
     ]
    }
   ],
   "source": [
    "#Not much of a change/ or improvement\n",
    "y_pred = LogReg.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  504\n",
      "False Positive - Spam:  3\n",
      "False Negative - Not Spam:  1\n",
      "True Positive - Spam:  92\n"
     ]
    }
   ],
   "source": [
    "#Similar to previous ones close to perfect but not there\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using a validation set\n",
    "#Validation Set of .1 \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=0)\n",
    "\n",
    "LogReg = LogisticRegression(solver='lbfgs',random_state=0)\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9933333333333333\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score stayed the same but it has 2 less false negatives!\n",
    "y_pred = LogReg.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  247\n",
      "False Positive - Spam:  0\n",
      "False Negative - Not Spam:  2\n",
      "True Positive - Spam:  51\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=5, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using a validation set with a random of 5\n",
    "#Validation Set of .1 \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=5)\n",
    "\n",
    "LogReg = LogisticRegression(solver='lbfgs',random_state=5)\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = LogReg.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  249\n",
      "False Positive - Spam:  1\n",
      "False Negative - Not Spam:  3\n",
      "True Positive - Spam:  47\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=10, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using a validation set with a random of 10\n",
    "#Validation Set of .1 \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=10)\n",
    "\n",
    "LogReg = LogisticRegression(solver='lbfgs',random_state=10)\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#A perfect prediction!  First one!\n",
    "y_pred = LogReg.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  262\n",
      "False Positive - Spam:  0\n",
      "False Negative - Not Spam:  0\n",
      "True Positive - Spam:  38\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=15, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using a validation set with a random of 15\n",
    "#Validation Set of .1 \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=15)\n",
    "\n",
    "LogReg = LogisticRegression(solver='lbfgs',random_state=15)\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "y_pred = LogReg.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  256\n",
      "False Positive - Spam:  0\n",
      "False Negative - Not Spam:  4\n",
      "True Positive - Spam:  40\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Naive Bayes classifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9416666666666667\n"
     ]
    }
   ],
   "source": [
    "y_pred = gnb.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  494\n",
      "False Positive - Spam:  16\n",
      "False Negative - Not Spam:  19\n",
      "True Positive - Spam:  71\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Naive Bayes classifier with random_state=10\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=10)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9616666666666667\n"
     ]
    }
   ],
   "source": [
    "y_pred = gnb.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  502\n",
      "False Positive - Spam:  5\n",
      "False Negative - Not Spam:  18\n",
      "True Positive - Spam:  75\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using a validation set\n",
    "#Validation Set of .1 \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=0)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "y_pred = gnb.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  254\n",
      "False Positive - Spam:  0\n",
      "False Negative - Not Spam:  16\n",
      "True Positive - Spam:  30\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Support Vector Machines\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995\n"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  510\n",
      "False Positive - Spam:  0\n",
      "False Negative - Not Spam:  3\n",
      "True Positive - Spam:  87\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using a validation set\n",
    "#Validation Set of .1 \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=0)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  254\n",
      "False Positive - Spam:  0\n",
      "False Negative - Not Spam:  3\n",
      "True Positive - Spam:  43\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuel.s/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With kernel='rbf'\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='rbf')\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8566666666666667\n"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  510\n",
      "False Positive - Spam:  0\n",
      "False Negative - Not Spam:  86\n",
      "True Positive - Spam:  4\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuel.s/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by changing value of Penalty parameter C of the error term to 10\n",
    "svclassifier = SVC(kernel='rbf', C = 10)\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935\n"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative - Not Spam:  509\n",
      "False Positive - Spam:  1\n",
      "False Negative - Not Spam:  38\n",
      "True Positive - Spam:  52\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Negative - Not Spam: \",tn)\n",
    "print(\"False Positive - Spam: \",fp)\n",
    "print(\"False Negative - Not Spam: \",fn)\n",
    "print(\"True Positive - Spam: \",tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
